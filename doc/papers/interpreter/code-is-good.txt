
Code is good.

When people first built language workbenches and wanted to define behavioral semantics for them, they thought that code was bad. This seemed obvious as the use of full-blown GPLs like C++ and Java introduced unsolvable problems involving analyzability (alias analysis, etc) and reverse engineering of high-level semantic concepts. DSL workbench developers turned towards more formal methods such as guarded commands, attribute grammars, abstract state machines, or rule-based transformations (operational semantics). Specialized DSLs were created to allow DSL semantics to be defined at a high level, often using the same language workbench it is meant to be a part of (eg ATL, xPand, Stratego/Spoofax, etc).

However, almost all of these DSLs eventually grow to duplicate of functionality from GPLs such as types, arrays and control flow, ultimately producing a language that is very close to a GPL but very slightly different [need cite]. The slight variations in syntax and structure impedes reuse of existing domain libraries while needlessly steepening the learning curve. Yet for all that bloat we still see essential language features omitted from such DSLs. ATL, for example, does not have generics, so the classic ATL example that transforms a family tree to list of persons can only be used to transform a company organization chart into a list of employees by copy-and-pasting the entire chunk of code and renaming the two labels.

Ultimately, language semantics is general computation, so why not just use an established general purpose language? That way we can reuse existing language features (and domain libraries) without reinventing yet another slightly different wheel.


But code is still bad.

Unfortunately, the problems of analyzability and retention of high-level concepts have not gone away. Hand-coded interpreters are essentially black boxes and it is impossible to make claims about their semantics without examining the implementation. Standard development tools from debuggers to refactoring engines to build scripts and version control, require semantic analysis at the level of the DSL. DSL-aware integrity and type checking, DSL-aware optimizations are only possible with high-level assumptions about how the DSL works.

An equally important, yet often overlooked, issue is that language design is a highly specialized task that even veteran programmers do not automatically excel at. Application programmers conscripted as toolsmiths under the language-oriented approach have little experience building DSLs, and giving them the freedom to write any kind of interpreters using code without any architectural guidelines can only result in inefficient interpreters and confusing semantics.


Eating your cake at a higher level

Our approach is to write interpreters using code, using large building blocks almost similar to a DSL. At the highest level, application programmers will be writing DSL-like code while still having all the features of the base programming languages at their disposal. Checkers and tools can work at this level and leverage the structure of the DSL exposed by the building blocks. If there is something that cannot be done at that level, the application programmer can pop back down to code and everything still integrates nicely.

